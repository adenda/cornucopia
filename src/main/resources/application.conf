
akka {
  actor {
    resharding-dispatcher {
      type = Dispatcher
      executor = "thread-pool-executor"

      thread-pool-executor {
        # minimum number of threads to cap factor-based core number to
        core-pool-size-min = 2
        # No of core threads ... ceil(available processors * factor)
        core-pool-size-factor = 256
        # maximum number of threads to cap factor-based number to
        core-pool-size-max = 2000
      }
    }

    deployment {
      /redisCommandRouter/migrationRouter {
        router = balancing-pool
        nr-of-instances = 5
        pool-dispatcher {
          executor = "thread-pool-executor"

          # allocate exactly 5 threads for this pool
          thread-pool-executor {
            core-pool-size-min = 5
            core-pool-size-max = 5
          }
        }
      }
    }

  }

  kafka {
    consumer {
      kafka-clients {
        auto.offset.reset = "earliest"
        enable.auto.commit = true
      }
    }
  }

}

cornucopia {

  // Time (seconds) to wait for hash-slot data to migrate before removing a master node.
  // The external node manager must ensure that the master node stays alive for at least this amount of time.
  // Any data not migrated during this period will be lost.
  //  GB-RAM / GBs-per-second-bandwidth ~= seconds
  // If you set this too low, you may see failures when performing any operation that involves redistributing hash slots.
  grace.period = 300

  // Time (seconds) to wait for cluster topology changes to propagate.
  refresh.timeout = 5

  // Time (seconds) to wait for batches to accumulate before executing a job.
  batch.period = 5

  // either `kafka` or `actor`
  source = "actor"

  // microservice type: `kafka` or `http`
  microservice.type = "http"

  http {
    host = "localhost"
    port = "9001"
  }

  reshard {
    // Mininum time (seconds) to wait between reshard events.
    interval = 60

    // the cluster must be resharded within this timeout, or else it fails
    timeout = 120

    // Each slot migration must complete before this time has elapsed
    migrate.slot.timeout = 60
  }
}

kafka {
  bootstrap.servers = "kafka-broker-1-vm:9092,kafka-broker-2-vm:9092"

  consumer {
    // Kafka topic to listen on.
    topic = "cornucopia"

    // Consumer group.
    group.id = "cluster-management"
  }
}

redis {
    cluster {
      // Initial node-hostname from which the full cluster topology will be derived.
      // This node must not be removed during operation of cornucopia.
      // Just one node because undefined behaviour occurs when you list nodes that are in disjoint cluster partitions.
      // Instead of failover capability, you end up with multiple points of failure.
      // Specifying multiple hosts is useful for an application but when building cluster it can be very messy.
      seed.server.host = "redis-seed-1"
      seed.server.port = 6379
    }
}